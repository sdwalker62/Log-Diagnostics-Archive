{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejXAKpdM7vpW"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZmbFWc97xsl"
   },
   "source": [
    "Feel free to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QLnvgfRy2U1H"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# -- Base -- #\n",
    "import os\n",
    "import joblib\n",
    "import logging\n",
    "import time\n",
    "import re\n",
    "import io\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import ipdb\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "\n",
    "# -- Metrics -- #\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3 as sql\n",
    "import tensorboard\n",
    "\n",
    "# -- Tensorflow -- #\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import MultiHeadAttention\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# -- Misc Models -- #\n",
    "import drain3\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# -- Dash -- #\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output, State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4L19JQx8YwmH"
   },
   "source": [
    "Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0N_5Z7Gg4Jl5"
   },
   "source": [
    "## Environmental Variables\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xvZC0zAR4NUe"
   },
   "outputs": [],
   "source": [
    "SOURCE = '/home/jovyan'\n",
    "\n",
    "# -- TRANSFORMER Pipeline -- #\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 1\n",
    "DROPOUT_RATE = 0.1\n",
    "MAX_SEQ_LEN = 200\n",
    "\n",
    "ACTIVATION = \"elu\"\n",
    "\n",
    "TRANSFORMER_LAYERS = 4\n",
    "TRANSFORMER_DFF = 2000\n",
    "TRANSFORMER_HEADS = 8\n",
    "\n",
    "TRAINING = True\n",
    "CONTAINER = 'core.soaesb'\n",
    "\n",
    "# -- WORD2VEC Pipeline -- #\n",
    "WINDOW_SIZE = 10\n",
    "GENERATE_NEW_DRAIN = True\n",
    "NUM_NEGATIVE_SAMPLING = 10\n",
    "W2V_BATCH_SIZE = 2048\n",
    "BUFFER_SIZE = 10000\n",
    "W2V_EPOCHS = 200\n",
    "W2V_EMBED_SIZE = 64\n",
    "MAX_VOCAB_SIZE = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "HM0ON9lGYvGe"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "# Set up logging.\n",
    "stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = SOURCE + 'logs/func/%s' % stamp\n",
    "writer = tf.summary.create_file_writer(logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2wOAfM3VZIWl"
   },
   "source": [
    "view graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4uJdL8IGZKdL"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir /content/drive/MyDrive/Work/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdlwPqq97n1m"
   },
   "source": [
    "Check if GPU is in use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "p1kUaw097qmg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May  1 04:43:10 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\n",
      "| 18%   55C    P0    40W / 215W |   2323MiB /  7979MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8EnuKFhAuER",
    "tags": []
   },
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GUivYRdyAstr"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logging' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;34m/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m, in \u001b[0;32mrun_code\u001b[0m:\nLine \u001b[0;34m3441\u001b[0m:  exec(code_obj, \u001b[36mself\u001b[39;49;00m.user_global_ns, \u001b[36mself\u001b[39;49;00m.user_ns)\n",
      "In  \u001b[0;34m[1]\u001b[0m:\nLine \u001b[0;34m1\u001b[0m:     logging.basicConfig(\u001b[36mformat\u001b[39;49;00m=\u001b[33m'\u001b[39;49;00m\u001b[33m%(asctime)s\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m%(levelname)s\u001b[39;49;00m\u001b[33m | \u001b[39;49;00m\u001b[33m%(message)s\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logging' is not defined\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(format='%(asctime)s %(levelname)s | %(message)s',\n",
    "                    level=logging.INFO,\n",
    "                    stream=sys.stdout)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITSJA5hWASDn",
    "tags": []
   },
   "source": [
    "# Define Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnCJ678Ka-T1"
   },
   "source": [
    "## Define Database Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gwi7HlrBkwwl"
   },
   "outputs": [],
   "source": [
    "def database_builder(path: str) -> pd.DataFrame():\n",
    "    logger.info('Building DataFrame ...')\n",
    "    (_, _, files) = next(os.walk(path))\n",
    "    sql_query = 'SELECT * FROM logs'\n",
    "    data = []\n",
    "    for f in files:\n",
    "        if '.db' in f:\n",
    "            conn = create_connection(path + f)\n",
    "            d = pd.read_sql_query(sql_query, conn)\n",
    "            data.append(d)\n",
    "    logger.info('...complete!')\n",
    "    return pd.concat(data)\n",
    "\n",
    "\n",
    "def create_connection(path: str) -> sql.Connection:\n",
    "    \"\"\"\n",
    "    Creates a database connection\n",
    "    :param path: str\n",
    "        path to database object\n",
    "    :return sql.Connection\n",
    "        a connection to the database\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sql.connect(path)\n",
    "        logger.info('Connected to database ' + path)\n",
    "        return conn\n",
    "    except sql.Error as e:\n",
    "        logger.warning(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekFXItHibG7r"
   },
   "source": [
    "## Define Dataset Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50ge2uap_kTN",
    "outputId": "af603cfd-5c79-4772-b0d7-9ab271eb4f4f"
   },
   "outputs": [],
   "source": [
    "dataset = database_builder(SOURCE + '/database/')\n",
    "container_dataset = dataset[dataset['container_name']==CONTAINER]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lkC2MdmCBR7C"
   },
   "source": [
    "# W2V Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wFAAOw-q3w5",
    "tags": []
   },
   "source": [
    "## Pipeline Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxst8UQeq8sL"
   },
   "source": [
    "### Standardize Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "FIbxj60aLAfC"
   },
   "outputs": [],
   "source": [
    "def standardize_logs(logs: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    # remove timestamps\n",
    "    logs['log'] = logs['log'].replace(\n",
    "        to_replace=r'(?:\\d{4}-\\d{2}-\\d{2}[\\sT]\\d{2}:\\d{2}:\\d{2}([.,]\\d{3}|\\s))|(?:\\s{2,})',\n",
    "        value=' ',\n",
    "        regex=True)\n",
    "    \n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QLKVLZioq_2i"
   },
   "source": [
    "### PhraseCaptureLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gFTBqUREEHLn"
   },
   "outputs": [],
   "source": [
    "class PhraseCaptureLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 min_count,\n",
    "                 threshold,\n",
    "                 load_model = False,\n",
    "                 save_model = True):\n",
    "\n",
    "        super(PhraseCaptureLayer, self).__init__()\n",
    "        self.min_count = min_count\n",
    "        self.threshold = threshold\n",
    "        self.load_model = load_model\n",
    "        self.save_model = save_model\n",
    "        \n",
    "        if self.load_model:\n",
    "            self.phrase_model = joblib.load(SOURCE + '/results/phrase_model.joblib')\n",
    "        else:\n",
    "            self.phrase_model = Phrases(min_count=self.min_count, threshold=self.threshold)\n",
    "\n",
    "    def call(self, corpus, training = True):\n",
    "\n",
    "        def clean_log(log):\n",
    "            log = log.lower().strip()\n",
    "            return re.sub(r'\\s{2,}', ' ', log)\n",
    "\n",
    "        def reorganize_return(corpus_with_phrases):\n",
    "            l = []\n",
    "            for tokenized_log in corpus_with_phrases:\n",
    "                l.append(' '.join(tokenized_log))\n",
    "            return l\n",
    "\n",
    "        split_corpus =[log.split(' ') for log in corpus['log']]\n",
    "        \n",
    "        if not training:\n",
    "            self.phrase_model = self.phrase_model.freeze()\n",
    "\n",
    "        self.phrase_model.add_vocab(split_corpus)\n",
    "\n",
    "        if self.save_model:\n",
    "            joblib.dump(self.phrase_model, SOURCE + '/results/phrase_model.joblib')\n",
    "        \n",
    "        corpus_with_phrases = self.phrase_model.__getitem__(split_corpus)\n",
    "        return reorganize_return(corpus_with_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eb6Ncm7-rKLZ"
   },
   "source": [
    "### TextClusteringLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nGOICjK9MtxY"
   },
   "outputs": [],
   "source": [
    "class TextClusteringLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, \n",
    "                 load_model = False,\n",
    "                 save_model = True):\n",
    "        \n",
    "        super(TextClusteringLayer, self).__init__()\n",
    "        self.load_model = load_model\n",
    "        self.save_model = save_model\n",
    "\n",
    "        if load_model:\n",
    "            self.template_miner = joblib.load(SOURCE + '/results/template_miner.joblib')\n",
    "        else:\n",
    "            self.template_miner = drain3.TemplateMiner()\n",
    "\n",
    "    def call(self, corpus, training = True):\n",
    "        if training:\n",
    "            for log in corpus:\n",
    "                self.template_miner.add_log_message(log)\n",
    "            if self.save_model:\n",
    "                joblib.dump(self.template_miner, SOURCE + '/results/template_miner.joblib')\n",
    "            \n",
    "            print(len(self.template_miner.drain.clusters))\n",
    "\n",
    "            return [re.sub(pattern=r' +',\n",
    "                       repl=' ',\n",
    "                       string=cluster.get_template())\n",
    "                    for cluster in self.template_miner.drain.clusters]\n",
    "        else: \n",
    "            l = []\n",
    "            for log in corpus:\n",
    "                match_cluster = self.template_miner.match(log)\n",
    "                if match_cluster is None:\n",
    "                    match_cluster = self.template_miner.add_log_message(log)\n",
    "                l.append(match_cluster)\n",
    "            return [re.sub(pattern=r' +',\n",
    "                       repl=' ',\n",
    "                       string=cluster.get_template())\n",
    "                    for cluster in l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jl_BXs9DrSA5"
   },
   "source": [
    "### NegativeSkipgramLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GAfbeuTcnFQK"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class NSLBundle:\n",
    "    vocab: dict\n",
    "    targets: list\n",
    "    contexts: list\n",
    "    labels: list\n",
    "\n",
    "class NegativeSkipgramLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 embedding_dim,\n",
    "                 window_size = 10,\n",
    "                 save_data = True):\n",
    "        \n",
    "        super(NegativeSkipgramLayer, self).__init__()\n",
    "        self.vocab_size = 0\n",
    "        self.vectorized_logs, self.corpus = [], []\n",
    "        self.targets, self.contexts, self.labels = [], [], []\n",
    "        self.vocab = {}\n",
    "        self.window_size = window_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.save_data = save_data\n",
    "\n",
    "    def collect_vocabulary(self):\n",
    "\n",
    "        idx = 1\n",
    "        self.vocab[0] = '<pad>'\n",
    "\n",
    "        log_tokenizer.fit_on_texts(self.corpus)\n",
    "        self.vectorized_logs = log_tokenizer.texts_to_sequences(self.corpus)\n",
    "\n",
    "        self.vocab.update({v: k for k, v in log_tokenizer.word_index.items()})\n",
    "        self.vocab_size = len(self.vocab.keys())\n",
    "\n",
    "    def find_word_context(self):\n",
    "\n",
    "        # Build the sampling table for vocab_size tokens.\n",
    "        sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(len(self.vocab))\n",
    "\n",
    "        for sequence in tqdm(self.vectorized_logs, position=0, leave=True):\n",
    "\n",
    "            positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "                sequence,\n",
    "                vocabulary_size=len(self.vocab),\n",
    "                sampling_table=sampling_table,\n",
    "                window_size=self.window_size,\n",
    "                negative_samples=0)\n",
    "\n",
    "            for target_word, context_word in positive_skip_grams:\n",
    "                context_class = tf.expand_dims(\n",
    "                    tf.constant([context_word], dtype='int64'), 1)\n",
    "\n",
    "                negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "                    true_classes=context_class,\n",
    "                    num_true=1,\n",
    "                    num_sampled=NUM_NEGATIVE_SAMPLING,\n",
    "                    unique=True,\n",
    "                    range_max=len(self.vocab),\n",
    "                    seed=42,\n",
    "                    name=\"negative_sampling\")\n",
    "\n",
    "                negative_sampling_candidates = tf.expand_dims(\n",
    "                    negative_sampling_candidates, 1)\n",
    "\n",
    "                context = tf.concat([context_class, negative_sampling_candidates], 0)\n",
    "                label = tf.constant([1] + [0] * NUM_NEGATIVE_SAMPLING, dtype='int64')\n",
    "\n",
    "                self.targets.append(target_word)\n",
    "                self.contexts.append(context)\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def call(self, corpus, training = True):\n",
    "\n",
    "        self.corpus = corpus\n",
    "        self.collect_vocabulary()\n",
    "        self.find_word_context()\n",
    "\n",
    "        if self.save_data:\n",
    "            joblib.dump(self.vocab, SOURCE + '/results/vocab.joblib')\n",
    "            joblib.dump(self.targets, SOURCE + '/results/targets.joblib')\n",
    "            joblib.dump(self.contexts, SOURCE + '/results/contexts.joblib')\n",
    "            joblib.dump(self.labels, SOURCE + '/results/labels.joblib')\n",
    "\n",
    "        return NSLBundle(self.vocab, self.targets, self.contexts, self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxXEjBM_rWYC"
   },
   "source": [
    "### Word2VecEmbeddingLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-JyKVfDf8CaP"
   },
   "outputs": [],
   "source": [
    "class Word2VecEmbeddingLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, \n",
    "                 embedding_dim,\n",
    "                 load_model = False, \n",
    "                 save_model = True):\n",
    "\n",
    "        super(Word2VecEmbeddingLayer, self).__init__()\n",
    "        self.embeddings = {}\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.load_model = load_model\n",
    "        self.save_model = save_model\n",
    "        self.Optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "        if load_model:\n",
    "            self.Word2Vec = load_model(SOURCE + '/results/word2vec')\n",
    "        else:\n",
    "            self.Word2Vec= None\n",
    "\n",
    "    def call(self, in_bundle, training):\n",
    "\n",
    "        vocab = in_bundle.vocab\n",
    "        targets = in_bundle.targets\n",
    "        contexts = in_bundle.contexts\n",
    "        labels = in_bundle.labels\n",
    "\n",
    "        if not self.load_model and self.Word2Vec is None:\n",
    "            self.Word2Vec = Word2Vec(len(vocab.keys()), self.embedding_dim)\n",
    "            self.Word2Vec.compile(\n",
    "                optimizer=self.Optimizer,\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n",
    "        dataset = dataset.shuffle(BUFFER_SIZE).batch(W2V_BATCH_SIZE, drop_remainder=True)\n",
    "        dataset = dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "        self.Word2Vec.fit(dataset, epochs=W2V_EPOCHS)\n",
    "        weights = self.Word2Vec.get_layer('w2v_embedding').get_weights()[0]\n",
    "\n",
    "        for word in vocab.items():\n",
    "            self.embeddings.update({\n",
    "                word[1]: weights[word[0]]\n",
    "                })\n",
    "\n",
    "        if self.save_model:\n",
    "            self.Word2Vec.save(SOURCE + '/results/word2vec')\n",
    "            out_v = io.open(SOURCE + '/results/vectors.tsv', 'w', encoding='utf-8')\n",
    "            out_m = io.open(SOURCE + '/results/metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "            for index, word in enumerate(vocab.values()):\n",
    "                if index == 0:\n",
    "                    continue  # skip 0, it's padding.\n",
    "                vec = weights[index]\n",
    "                out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "                out_m.write(word + \"\\n\")\n",
    "            out_v.close()\n",
    "            out_m.close()\n",
    "\n",
    "        self.Word2Vec.summary()\n",
    "        return self.embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hQRAbPfrZwt"
   },
   "source": [
    "### Word2VecModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "H_GiqTup8AY3"
   },
   "outputs": [],
   "source": [
    "class Word2Vec(tf.keras.models.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Word2Vec, self).__init__()\n",
    "        self.target_embedding = tf.keras.layers.Embedding(\n",
    "            vocab_size,\n",
    "            embedding_dim,\n",
    "            input_length=1, # input length 1 since we are focusing on one token\n",
    "            name=\"w2v_embedding\")\n",
    "\n",
    "        self.context_embedding = tf.keras.layers.Embedding(\n",
    "            vocab_size,\n",
    "            embedding_dim,\n",
    "            input_length=NUM_NEGATIVE_SAMPLING + 1) # window size for contextual \n",
    "            # reasoning behind the sample token\n",
    "        self.dots = tf.keras.layers.Dot(axes=(3, 2))\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "    def call(self, pair):\n",
    "        target, context = pair\n",
    "        we = self.target_embedding(target)\n",
    "        ce = self.context_embedding(context)\n",
    "        dots = self.dots([ce, we])\n",
    "        return self.flatten(dots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OvhQ3bvitv5b"
   },
   "source": [
    "### W2V_Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "R_nmehscsdmv"
   },
   "outputs": [],
   "source": [
    "class W2V_Pipeline(tf.keras.Model):\n",
    "    def __init__(self, \n",
    "                 save_model,\n",
    "                 load_model):\n",
    "        \n",
    "        super(W2V_Pipeline, self).__init__()\n",
    "        self.save_model = save_model\n",
    "        self.load_model = load_model\n",
    "        \n",
    "        self.PCL = PhraseCaptureLayer(\n",
    "            5, 7, \n",
    "            load_model=load_model, \n",
    "            save_model=save_model)\n",
    "        \n",
    "        self.TCL = TextClusteringLayer(\n",
    "            load_model=load_model, \n",
    "            save_model=save_model)\n",
    "        \n",
    "        self.NSL = NegativeSkipgramLayer(W2V_EMBED_SIZE)\n",
    "\n",
    "        self.W2V = Word2VecEmbeddingLayer(\n",
    "            W2V_EMBED_SIZE, \n",
    "            load_model=load_model, \n",
    "            save_model=save_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = standardize_logs(x)\n",
    "        x = self.PCL(x)\n",
    "        x = self.TCL(x)\n",
    "        x = self.NSL(x)\n",
    "        return self.W2V(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>container_name</th>\n",
       "      <th>log</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-01-29T18:07:13.134Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-29T18:07:08,402 | INFO  | aging/0-SNAP...</td>\n",
       "      <td>nitf-messaging-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2021-01-29T18:07:13.134Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-29T18:07:08,402 | INFO  | aging/0-SNAP...</td>\n",
       "      <td>nitf-messaging-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2021-01-29T18:07:13.134Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-29T18:07:05,257 | INFO  | ev.HealthMon...</td>\n",
       "      <td>nitf-messaging-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2021-01-29T18:07:13.134Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-29T18:07:08,245 | INFO  | aging/0-SNAP...</td>\n",
       "      <td>nitf-messaging-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>2021-01-29T18:07:13.134Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-29T18:07:05,257 | INFO  | ev.HealthMon...</td>\n",
       "      <td>nitf-messaging-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>2021-01-29T18:07:13.134Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-29T18:07:07,956 | INFO  | b]-nio2-thre...</td>\n",
       "      <td>nitf-messaging-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>2021-01-29T18:07:13.134Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-29T18:07:07,956 | INFO  | b]-nio2-thre...</td>\n",
       "      <td>nitf-messaging-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>2021-01-29T18:07:13.134Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-29T18:07:08,245 | INFO  | aging/0-SNAP...</td>\n",
       "      <td>nitf-messaging-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>2021-01-29T18:07:38.143Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-29T18:07:35,260 | INFO  | ev.HealthMon...</td>\n",
       "      <td>nitf-messaging-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>2021-01-29T18:07:38.143Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-29T18:07:35,260 | INFO  | ev.HealthMon...</td>\n",
       "      <td>nitf-messaging-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>2021-01-29T18:08:20.167Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-29T18:08:17,955 | INFO  | scene/0-SNAP...</td>\n",
       "      <td>newscene-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>2021-01-29T18:09:10.178Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-29T18:09:05,267 | INFO  | ev.HealthMon...</td>\n",
       "      <td>newscene-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>2021-01-29T18:08:20.167Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-29T18:08:17,613 | INFO  | b]-nio2-thre...</td>\n",
       "      <td>newscene-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>2021-01-29T18:08:45.172Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-29T18:08:35,266 | INFO  | ev.HealthMon...</td>\n",
       "      <td>newscene-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>2021-01-29T18:08:45.172Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-29T18:08:35,266 | INFO  | ev.HealthMon...</td>\n",
       "      <td>newscene-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>2021-01-29T18:09:10.178Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-29T18:09:05,267 | INFO  | ev.HealthMon...</td>\n",
       "      <td>newscene-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2021-01-29T18:08:20.167Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-29T18:08:17,613 | INFO  | b]-nio2-thre...</td>\n",
       "      <td>newscene-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>2021-01-29T18:08:20.167Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-29T18:08:17,955 | INFO  | scene/0-SNAP...</td>\n",
       "      <td>newscene-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>2021-01-29T18:09:25.185Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-29T18:09:21,229 | INFO  | scene/0-SNAP...</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>2021-01-29T18:09:25.185Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-29T18:09:20,828 | INFO  | b]-nio2-thre...</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>2021-01-29T18:09:25.185Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-29T18:09:21,229 | INFO  | scene/0-SNAP...</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>2021-01-29T18:09:25.185Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-29T18:09:20,828 | INFO  | b]-nio2-thre...</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>2021-01-29T18:10:35.196Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-29T18:10:33,357 | INFO  | Framework st...</td>\n",
       "      <td>core.soaesb-dead-soa-process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>2021-01-29T18:10:35.196Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-29T18:10:33,367 | INFO  | Framework st...</td>\n",
       "      <td>core.soaesb-dead-soa-process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>2021-01-29T18:10:35.196Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-29T18:10:33,394 | INFO  | Framework st...</td>\n",
       "      <td>core.soaesb-dead-soa-process</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     timestamp container_name  \\\n",
       "9     2021-01-29T18:07:13.134Z    core.soaesb   \n",
       "64    2021-01-29T18:07:13.134Z    core.soaesb   \n",
       "65    2021-01-29T18:07:13.134Z    core.soaesb   \n",
       "182   2021-01-29T18:07:13.134Z    core.soaesb   \n",
       "369   2021-01-29T18:07:13.134Z    core.soaesb   \n",
       "370   2021-01-29T18:07:13.134Z    core.soaesb   \n",
       "435   2021-01-29T18:07:13.134Z    core.soaesb   \n",
       "487   2021-01-29T18:07:13.134Z    core.soaesb   \n",
       "537   2021-01-29T18:07:38.143Z    core.soaesb   \n",
       "589   2021-01-29T18:07:38.143Z    core.soaesb   \n",
       "630   2021-01-29T18:08:20.167Z    core.soaesb   \n",
       "675   2021-01-29T18:09:10.178Z    core.soaesb   \n",
       "687   2021-01-29T18:08:20.167Z    core.soaesb   \n",
       "714   2021-01-29T18:08:45.172Z    core.soaesb   \n",
       "784   2021-01-29T18:08:45.172Z    core.soaesb   \n",
       "970   2021-01-29T18:09:10.178Z    core.soaesb   \n",
       "997   2021-01-29T18:08:20.167Z    core.soaesb   \n",
       "1180  2021-01-29T18:08:20.167Z    core.soaesb   \n",
       "1226  2021-01-29T18:09:25.185Z    core.soaesb   \n",
       "1290  2021-01-29T18:09:25.185Z    core.soaesb   \n",
       "1442  2021-01-29T18:09:25.185Z    core.soaesb   \n",
       "1514  2021-01-29T18:09:25.185Z    core.soaesb   \n",
       "1547  2021-01-29T18:10:35.196Z    core.soaesb   \n",
       "1548  2021-01-29T18:10:35.196Z    core.soaesb   \n",
       "1549  2021-01-29T18:10:35.196Z    core.soaesb   \n",
       "\n",
       "                                                    log  \\\n",
       "9     2021-01-29T18:07:08,402 | INFO  | aging/0-SNAP...   \n",
       "64    2021-01-29T18:07:08,402 | INFO  | aging/0-SNAP...   \n",
       "65    2021-01-29T18:07:05,257 | INFO  | ev.HealthMon...   \n",
       "182   2021-01-29T18:07:08,245 | INFO  | aging/0-SNAP...   \n",
       "369   2021-01-29T18:07:05,257 | INFO  | ev.HealthMon...   \n",
       "370   2021-01-29T18:07:07,956 | INFO  | b]-nio2-thre...   \n",
       "435   2021-01-29T18:07:07,956 | INFO  | b]-nio2-thre...   \n",
       "487   2021-01-29T18:07:08,245 | INFO  | aging/0-SNAP...   \n",
       "537   2021-01-29T18:07:35,260 | INFO  | ev.HealthMon...   \n",
       "589   2021-01-29T18:07:35,260 | INFO  | ev.HealthMon...   \n",
       "630   2021-01-29T18:08:17,955 | INFO  | scene/0-SNAP...   \n",
       "675   2021-01-29T18:09:05,267 | INFO  | ev.HealthMon...   \n",
       "687   2021-01-29T18:08:17,613 | INFO  | b]-nio2-thre...   \n",
       "714   2021-01-29T18:08:35,266 | INFO  | ev.HealthMon...   \n",
       "784   2021-01-29T18:08:35,266 | INFO  | ev.HealthMon...   \n",
       "970   2021-01-29T18:09:05,267 | INFO  | ev.HealthMon...   \n",
       "997   2021-01-29T18:08:17,613 | INFO  | b]-nio2-thre...   \n",
       "1180  2021-01-29T18:08:17,955 | INFO  | scene/0-SNAP...   \n",
       "1226  2021-01-29T18:09:21,229 | INFO  | scene/0-SNAP...   \n",
       "1290  2021-01-29T18:09:20,828 | INFO  | b]-nio2-thre...   \n",
       "1442  2021-01-29T18:09:21,229 | INFO  | scene/0-SNAP...   \n",
       "1514  2021-01-29T18:09:20,828 | INFO  | b]-nio2-thre...   \n",
       "1547  2021-01-29T18:10:33,357 | INFO  | Framework st...   \n",
       "1548  2021-01-29T18:10:33,367 | INFO  | Framework st...   \n",
       "1549  2021-01-29T18:10:33,394 | INFO  | Framework st...   \n",
       "\n",
       "                              label  \n",
       "9     nitf-messaging-bundle-stopped  \n",
       "64    nitf-messaging-bundle-stopped  \n",
       "65    nitf-messaging-bundle-stopped  \n",
       "182   nitf-messaging-bundle-stopped  \n",
       "369   nitf-messaging-bundle-stopped  \n",
       "370   nitf-messaging-bundle-stopped  \n",
       "435   nitf-messaging-bundle-stopped  \n",
       "487   nitf-messaging-bundle-stopped  \n",
       "537   nitf-messaging-bundle-stopped  \n",
       "589   nitf-messaging-bundle-stopped  \n",
       "630         newscene-bundle-stopped  \n",
       "675         newscene-bundle-stopped  \n",
       "687         newscene-bundle-stopped  \n",
       "714         newscene-bundle-stopped  \n",
       "784         newscene-bundle-stopped  \n",
       "970         newscene-bundle-stopped  \n",
       "997         newscene-bundle-stopped  \n",
       "1180        newscene-bundle-stopped  \n",
       "1226                        healthy  \n",
       "1290                        healthy  \n",
       "1442                        healthy  \n",
       "1514                        healthy  \n",
       "1547   core.soaesb-dead-soa-process  \n",
       "1548   core.soaesb-dead-soa-process  \n",
       "1549   core.soaesb-dead-soa-process  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container_dataset.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fiNfWpckbW3A"
   },
   "source": [
    "## W2V Pipeline Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ll4n92B5rGYW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-03 16:19:52,480 INFO | Starting Drain3 template miner\n",
      "2021-05-03 16:19:52,481 INFO | Loading configuration from drain3.ini\n",
      "2021-05-03 16:19:52,489 WARNING | config file not found: drain3.ini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-e5ecdb34ad29>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  logs['log'] = logs['log'].replace(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-03 16:19:54,742 INFO | collecting all words and their counts\n",
      "2021-05-03 16:19:54,743 INFO | PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2021-05-03 16:19:55,461 INFO | PROGRESS: at sentence #10000, processed 292290 words and 7920 word types\n",
      "2021-05-03 16:19:56,091 INFO | PROGRESS: at sentence #20000, processed 585850 words and 12008 word types\n",
      "2021-05-03 16:19:56,547 INFO | collected 16000 token types (unigram + bigrams) from a corpus of 827523 words and 28226 sentences\n",
      "2021-05-03 16:19:56,548 INFO | merged Phrases<16000 vocab, min_count=5, threshold=7, max_vocab_size=40000000>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/44 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 55.64it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 1s 638ms/step - loss: 2.3980 - accuracy: 0.1050\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3969 - accuracy: 0.1348\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3958 - accuracy: 0.1758\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.3947 - accuracy: 0.2129\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.3936 - accuracy: 0.2510\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.3924 - accuracy: 0.2900\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.3912 - accuracy: 0.3306\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.3899 - accuracy: 0.3716\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.3886 - accuracy: 0.4272\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.3873 - accuracy: 0.4785\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.3858 - accuracy: 0.5107\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.3844 - accuracy: 0.5483\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.3828 - accuracy: 0.5684\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.3811 - accuracy: 0.5913\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.3794 - accuracy: 0.6108\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.3776 - accuracy: 0.6230\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.3757 - accuracy: 0.6333\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.3737 - accuracy: 0.6362\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.3716 - accuracy: 0.6431\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.3693 - accuracy: 0.6509\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.3670 - accuracy: 0.6523\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.3645 - accuracy: 0.6567\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.3619 - accuracy: 0.6587\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.3592 - accuracy: 0.6616\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.3564 - accuracy: 0.6660\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.3534 - accuracy: 0.6655\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.3503 - accuracy: 0.6680\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.3470 - accuracy: 0.6680\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.3436 - accuracy: 0.6714\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.3401 - accuracy: 0.6704\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.3364 - accuracy: 0.6694\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.3325 - accuracy: 0.6694\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.3284 - accuracy: 0.6694\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.3242 - accuracy: 0.6689\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.3199 - accuracy: 0.6704\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3153 - accuracy: 0.6704\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.3106 - accuracy: 0.6714\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.3058 - accuracy: 0.6694\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.3007 - accuracy: 0.6670\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.2955 - accuracy: 0.6636\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.2900 - accuracy: 0.6626\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.2844 - accuracy: 0.6606\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.2786 - accuracy: 0.6606\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.2727 - accuracy: 0.6606\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2665 - accuracy: 0.65 - 0s 22ms/step - loss: 2.2665 - accuracy: 0.6582\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.2601 - accuracy: 0.6577\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.2536 - accuracy: 0.6572\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2469 - accuracy: 0.6577\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2400 - accuracy: 0.6572\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2329 - accuracy: 0.6572\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2256 - accuracy: 0.6567\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.2181 - accuracy: 0.6558\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.2104 - accuracy: 0.6543\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.2026 - accuracy: 0.6533\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.1945 - accuracy: 0.6528\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.1863 - accuracy: 0.6523\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.1779 - accuracy: 0.6528\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.1694 - accuracy: 0.6509\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1606 - accuracy: 0.6489\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.1517 - accuracy: 0.6489\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.1426 - accuracy: 0.6475\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.1334 - accuracy: 0.6470\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1240 - accuracy: 0.6475\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1144 - accuracy: 0.6475\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.1047 - accuracy: 0.6465\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.0948 - accuracy: 0.6455\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.0848 - accuracy: 0.6450\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0746 - accuracy: 0.6450\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.0643 - accuracy: 0.6445\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.0539 - accuracy: 0.6440\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.0433 - accuracy: 0.6431\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.0327 - accuracy: 0.6426\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.0219 - accuracy: 0.6426\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.0110 - accuracy: 0.6401\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.0000 - accuracy: 0.6401\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.9889 - accuracy: 0.6387\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.9777 - accuracy: 0.6387\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.9664 - accuracy: 0.6377\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.9551 - accuracy: 0.6367\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.9436 - accuracy: 0.6367\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.9321 - accuracy: 0.6367\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.9206 - accuracy: 0.6357\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.9090 - accuracy: 0.6348\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.8973 - accuracy: 0.6353\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.8856 - accuracy: 0.6362\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.8739 - accuracy: 0.6357\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.8621 - accuracy: 0.6362\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.8503 - accuracy: 0.6357\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.8385 - accuracy: 0.6367\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.8267 - accuracy: 0.6372\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.8149 - accuracy: 0.6372\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.8031 - accuracy: 0.6392\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.7913 - accuracy: 0.6396\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.7795 - accuracy: 0.6406\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.7677 - accuracy: 0.6406\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.7560 - accuracy: 0.6401\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.7442 - accuracy: 0.6416\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.7325 - accuracy: 0.6421\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.7209 - accuracy: 0.6426\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.7092 - accuracy: 0.6426\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.6976 - accuracy: 0.6436\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.6861 - accuracy: 0.6440\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.6746 - accuracy: 0.6440\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.6632 - accuracy: 0.6445\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.6518 - accuracy: 0.6455\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.6405 - accuracy: 0.6455\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.6293 - accuracy: 0.6470\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.6181 - accuracy: 0.6489\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6070 - accuracy: 0.6494\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.5960 - accuracy: 0.6509\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5850 - accuracy: 0.6523\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5741 - accuracy: 0.6528\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.5633 - accuracy: 0.6533\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5526 - accuracy: 0.6553\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5419 - accuracy: 0.6553\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.5314 - accuracy: 0.6553\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.5209 - accuracy: 0.6567\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5105 - accuracy: 0.6572\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.5002 - accuracy: 0.6577\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4900 - accuracy: 0.6587\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.4799 - accuracy: 0.6621\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.4698 - accuracy: 0.6621\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.4599 - accuracy: 0.6646\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4500 - accuracy: 0.6646\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4402 - accuracy: 0.6660\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4306 - accuracy: 0.6685\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4210 - accuracy: 0.6689\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4115 - accuracy: 0.6704\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.4021 - accuracy: 0.6733\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3928 - accuracy: 0.6743\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3836 - accuracy: 0.6763\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3745 - accuracy: 0.6772\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3654 - accuracy: 0.6768\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.3565 - accuracy: 0.6777\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3476 - accuracy: 0.6777\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3389 - accuracy: 0.6787\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3302 - accuracy: 0.6787\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3216 - accuracy: 0.6797\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3132 - accuracy: 0.6807\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.3048 - accuracy: 0.6831\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2965 - accuracy: 0.6851\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2883 - accuracy: 0.6860\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.2801 - accuracy: 0.6865\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2721 - accuracy: 0.6880\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2642 - accuracy: 0.6885\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2563 - accuracy: 0.6909\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2485 - accuracy: 0.6924\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2409 - accuracy: 0.6938\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2333 - accuracy: 0.6953\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2258 - accuracy: 0.6958\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.2183 - accuracy: 0.6968\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2110 - accuracy: 0.6987\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2037 - accuracy: 0.69 - 0s 17ms/step - loss: 1.2037 - accuracy: 0.6982\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1966 - accuracy: 0.7002\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1895 - accuracy: 0.7007\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.1824 - accuracy: 0.7021\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.1755 - accuracy: 0.7026\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1687 - accuracy: 0.7056\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.1619 - accuracy: 0.7061\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1552 - accuracy: 0.7070\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1486 - accuracy: 0.7090\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.1420 - accuracy: 0.7104\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1356 - accuracy: 0.7129\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1292 - accuracy: 0.7134\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.1228 - accuracy: 0.7148\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1166 - accuracy: 0.7158\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.1104 - accuracy: 0.7173\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1043 - accuracy: 0.7173\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0983 - accuracy: 0.7183\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0923 - accuracy: 0.7192\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0864 - accuracy: 0.7217\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0806 - accuracy: 0.7231\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0748 - accuracy: 0.7246\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.0691 - accuracy: 0.7251\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.0635 - accuracy: 0.7261\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0579 - accuracy: 0.7275\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.0524 - accuracy: 0.7280\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.0469 - accuracy: 0.7310\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.0415 - accuracy: 0.7319\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0362 - accuracy: 0.7329\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0309 - accuracy: 0.7339\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0257 - accuracy: 0.7363\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0206 - accuracy: 0.7368\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.0154 - accuracy: 0.7378\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.0104 - accuracy: 0.7388\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0054 - accuracy: 0.7388\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0005 - accuracy: 0.7393\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9956 - accuracy: 0.7397\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.9907 - accuracy: 0.7407\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9860 - accuracy: 0.7422\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.9812 - accuracy: 0.7437\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.9765 - accuracy: 0.7451\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9719 - accuracy: 0.7461\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9673 - accuracy: 0.7461\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.9628 - accuracy: 0.7471\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9583 - accuracy: 0.7476\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9538 - accuracy: 0.7490\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.9494 - accuracy: 0.7495\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9450 - accuracy: 0.7500\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9407 - accuracy: 0.7510\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/results/word2vec/assets\n",
      "2021-05-03 16:20:17,127 INFO | Assets written to: /home/jovyan/results/word2vec/assets\n",
      "Model: \"word2_vec\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "w2v_embedding (Embedding)    multiple                  34176     \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        multiple                  34176     \n",
      "_________________________________________________________________\n",
      "dot (Dot)                    multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "=================================================================\n",
      "Total params: 68,352\n",
      "Trainable params: 68,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ** Preprocessing **\n",
    "'''\n",
    "standardize_logs \n",
    "'''\n",
    "\n",
    "# ** Model **\n",
    "# 1. \n",
    "# LogTokenEmbedder\n",
    "'''\n",
    "Seq = [PCL\n",
    "       TCL \n",
    "       NSL\n",
    "       GT1: W2V] -> {embedding_matrix, vocab} \n",
    "'''\n",
    "######\n",
    "\n",
    "# 2.\n",
    "# Transformer Stuff \n",
    "'''\n",
    "{log, embedding_matrix, vocab} ->\n",
    "GT2: Transformer -> prediction \n",
    "'''\n",
    "#LOG_DIR = SOURCE + 'logs'\n",
    "#metadata = os.path.join(LOG_DIR, 'metadata.tsv')\n",
    "#config = projector.ProjectorConfig()\n",
    "\n",
    "log_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='')\n",
    "w2vp = W2V_Pipeline(load_model = False, save_model = True)\n",
    "embed_weights = w2vp(container_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWSpd9MecA8b"
   },
   "source": [
    "## W2V Dash "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRGlsN0McF1D"
   },
   "source": [
    "### W2V Dash Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "l9AAeUOmnz4h"
   },
   "outputs": [],
   "source": [
    "def tree_parser(node, l, m, root_node):\n",
    "    d = node.key_to_child_node # dict\n",
    "    for token in list(d.keys()):\n",
    "        if len(root_node.key_to_child_node.keys()) == 0:\n",
    "            ret_list = []\n",
    "            for row in m:\n",
    "                proper_len = int(row[1])\n",
    "                if len(row) == proper_len+1:\n",
    "                  ret_list.append(row)\n",
    "            return ret_list\n",
    "        l.append(token)\n",
    "        child = d[token]\n",
    "        if child.key_to_child_node:\n",
    "            tree_parser(child, l, m, root_node)\n",
    "        else:\n",
    "            d.pop(token)\n",
    "            m.append(l)\n",
    "            l = ['root']\n",
    "            tree_parser(root_node, l, m, root_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRaXmjdkcvVm"
   },
   "source": [
    "### W2V Dash Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCgMbFevmC88"
   },
   "source": [
    "The output of the W2V pipeline is a matrix of size [vocab size x embedding size] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "jw4mwJz6eGa6"
   },
   "outputs": [],
   "source": [
    "# -- W2V Dash Environmental Variables -- #\n",
    "\n",
    "W2V_NEIGHBORS = 20\n",
    "RECURSION_LIMIT = 10**6\n",
    "N_PROJ_DIM = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "a60tfcLUoERG"
   },
   "outputs": [],
   "source": [
    "# -- Generate Data for Word Embeddings Projector -- #\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# shape = vocab size x embedding dim size\n",
    "weights = np.ndarray(shape=(len(embed_weights), W2V_EMBED_SIZE)) \n",
    "pca = PCA(n_components=N_PROJ_DIM)\n",
    "\n",
    "# -- Populate Matrix for PCA -- #\n",
    "for idx, weight in enumerate(list(embed_weights.values())):\n",
    "    weights[idx, :] = weight \n",
    "\n",
    "reduced_embeddings = pca.fit_transform(weights)\n",
    "\n",
    "# -- Calculate Nearest Neighbors -- #\n",
    "embeddings_knn = NearestNeighbors(n_neighbors=W2V_NEIGHBORS, algorithm='auto')\n",
    "embeddings_knn_trained = embeddings_knn.fit(reduced_embeddings)\n",
    "\n",
    "# Currently the array has a shape of vocab size x N_PROJ_DIM and contains\n",
    "# the fitted PCA data. We need to add the vocab in the first column so \n",
    "# we know which vectors are represented. \n",
    "embedding_vocab_arr = np.array(list((embed_weights.keys())))\n",
    "embedding_vocab_arr = np.expand_dims(embedding_vocab_arr, 1)\n",
    "reduced_embeddings = np.hstack((embedding_vocab_arr, reduced_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GC17hivjjKs0"
   },
   "source": [
    "We will build our plot using the tree_parser function. This function recursively\n",
    "steps through the drain3.TemplateMiner.drain.Node structure of our \n",
    "**TextClusteringLayer** (TCL). The recursion populates a np.array which is then used\n",
    "to build a pandas dataframe which the plotly treemap accepts. There is a column\n",
    "appended to the tail of the dataframe which counts the number of stars \n",
    "(wild card masks) present in the row. This is used to define the colors shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "X7TkKEOFyRH3"
   },
   "outputs": [],
   "source": [
    "# -- Generate Data for Treemap -- #\n",
    "\n",
    "# By default python's recursion limit is 10**4 which is too small for our needs\n",
    "sys.setrecursionlimit(RECURSION_LIMIT)\n",
    "\n",
    "'''\n",
    "We start by defining the head of our tree which is root. The list m is our \n",
    "master list for recording the paths in the tree. Each path is another list \n",
    "stored here.\n",
    "'''\n",
    "\n",
    "l = ['root']\n",
    "m = []\n",
    "\n",
    "# The root node is the master node of the tree and will be our return point\n",
    "root_node = deepcopy(w2vp.TCL.template_miner.drain.root_node)\n",
    "\n",
    "parsed_tree = tree_parser(root_node, l, m, root_node)\n",
    "parsed_tree_df = pd.DataFrame(data=parsed_tree)\n",
    "\n",
    "# The returned dataframe has generic columns so we will provide custom labels\n",
    "n_cols = len(parsed_tree_df.columns)\n",
    "col_name_list = []\n",
    "for idx in range(n_cols):\n",
    "    col_name_list.append('level' + str(idx))\n",
    "parsed_tree_df.columns = col_name_list\n",
    "\n",
    "'''\n",
    "Without a color column our treemap would just be plain. We thought that taking \n",
    "the sum of the drain mask would be an interesting way to color the treemap. This\n",
    "lambda function will sum those values in each row and return them to a new \n",
    "columnn named 'sum'\n",
    "'''\n",
    "parsed_tree_df['sum'] = parsed_tree_df.apply(lambda x: x.str.contains('<*>'), axis=1).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tree_parser(root_node, l, m, root_node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "Je-dqJAGlzA9"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-c71319de0d1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# -- TreeMap -- #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mlog_treemap_fig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtreemap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_tree_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol_name_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/plotly/express/_chart_types.py\u001b[0m in \u001b[0;36mtreemap\u001b[0;34m(data_frame, names, values, parents, ids, path, color, color_continuous_scale, range_color, color_continuous_midpoint, color_discrete_sequence, color_discrete_map, hover_name, hover_data, custom_data, labels, title, template, width, height, branchvalues, maxdepth)\u001b[0m\n\u001b[1;32m   1462\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbranchvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m         \u001b[0mbranchvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"total\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1464\u001b[0;31m     return make_figure(\n\u001b[0m\u001b[1;32m   1465\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m         \u001b[0mconstructor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTreemap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/plotly/express/_core.py\u001b[0m in \u001b[0;36mmake_figure\u001b[0;34m(args, constructor, trace_patch, layout_patch)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstructor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconstructor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTreemap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSunburst\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_dataframe_hierarchy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconstructor\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"timeline\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0mconstructor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/plotly/express/_core.py\u001b[0m in \u001b[0;36mprocess_dataframe_hierarchy\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data_frame\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1502\u001b[0;31m     \u001b[0m_check_dataframe_all_leaves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1503\u001b[0m     \u001b[0mdiscrete_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/plotly/express/_core.py\u001b[0m in \u001b[0;36m_check_dataframe_all_leaves\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m   1471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_dataframe_all_leaves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1473\u001b[0;31m     \u001b[0mdf_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m     \u001b[0mnull_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_sorted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m     \u001b[0mdf_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_sorted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   5452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5454\u001b[0;31m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5455\u001b[0m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import dash\n",
    "import plotly.express as px\n",
    "from dash.dependencies import Input, Output, State\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import json\n",
    "import dash_table\n",
    "import plotly.io as pio\n",
    "from dash import no_update\n",
    "\n",
    "\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "external_stylesheets = ['https://drive.google.com/uc?export=view&id=19OXGQ5iJIjRZD4VEZ-xiVChDmj0-SlSF']\n",
    "#['http://127.0.0.1:8888/lab/tree/assets/metrics.min.css']\n",
    "#['https://drive.google.com/uc?export=view&id=19OXGQ5iJIjRZD4VEZ-xiVChDmj0-SlSF']\n",
    "\n",
    "\n",
    "app = JupyterDash(__name__, external_stylesheets=external_stylesheets)\n",
    "\n",
    "\n",
    "# -- Scatter Plot -- #\n",
    "\n",
    "scatter3d_cols = ['token', 'x1', 'x2', 'x3']\n",
    "scatter3d_df = pd.DataFrame(data=reduced_embeddings, columns=scatter3d_cols)\n",
    "\n",
    "# We want to ensure that the coordinates are numerical \n",
    "scatter3d_df['x1'] = pd.to_numeric(scatter3d_df['x1'])\n",
    "scatter3d_df['x2'] = pd.to_numeric(scatter3d_df['x2'])\n",
    "scatter3d_df['x3'] = pd.to_numeric(scatter3d_df['x3'])\n",
    "\n",
    "# This figure will contain non selected data points\n",
    "scatter3d_fig = px.scatter_3d(\n",
    "    scatter3d_df,\n",
    "    x='x1', \n",
    "    y='x2', \n",
    "    z='x3',\n",
    "    hover_name='token')\n",
    "\n",
    "scatter3d_fig.update_traces(marker=dict(size=5, line=dict(width=2, color='DarkSlateGrey')))\n",
    "scatter3d_fig['layout']['uirevision'] = 1\n",
    "                                         \n",
    "                                         \n",
    "# -- TreeMap -- #\n",
    "\n",
    "log_treemap_fig = px.treemap(parsed_tree_df, path=col_name_list, color='sum')\n",
    "table = pd.DataFrame(data=list(embed_weights.keys()), columns=['token'])\n",
    "\n",
    "\n",
    "# -- Dash App Logic -- #\n",
    "\n",
    "app.layout = html.Div([\n",
    "    \n",
    "        html.Div(dcc.Graph(id = '3d_scat', figure=scatter3d_fig, config={'responsive': True}, style={'height': '100%', 'width': '100%'}\n",
    "        ), className='main-graph-container', id='graph_div'),\n",
    "    \n",
    "        html.Div(dcc.Graph(id = 'treemap', figure=log_treemap_fig, config={'responsive': True}, style={'height': '100%', 'width': '100%'}\n",
    "        ), className='secondary-graph-container', id='tree_div'),\n",
    "    \n",
    "        html.Div(className='related-graph', id = 'data_table',\n",
    "                 children=[dash_table.DataTable(\n",
    "                     id='table',\n",
    "                     columns=[{\"name\": i, \"id\": i} for i in table.columns],\n",
    "                     data=pd.DataFrame().to_dict('records'),\n",
    "                     style_cell={'textAlign': 'left', \n",
    "                                 'overflow': 'hidden',\n",
    "                                 'textOverflow': 'ellipsis',\n",
    "                                 'maxWidth': 0,\n",
    "                                 'backgroundColor': 'rgb(50, 50, 50)',\n",
    "                                 'color': 'white'},\n",
    "                     style_header={'backgroundColor': 'rgb(30, 30, 30)'},\n",
    "                 )]\n",
    "        )], id=\"report-container\", className='flex-grid')\n",
    "\n",
    "# style_data={'height': 'auto', 'lineHeight': '15px'}\n",
    "                    # style_table={'height': 'auto'},\n",
    "                    # table.to_dict('records')\n",
    "# global_update = None\n",
    "# html.Div(className='color3', id='logger', children=[html.P(children=\"this is a temporary log\", id='logger_text')])\n",
    "\n",
    "\n",
    "# -- App Callbacks -- #\n",
    "\n",
    "@app.callback(Output(\"table\", \"data\"),\n",
    "              Output(\"3d_scat\", \"figure\"),\n",
    "            Input('3d_scat', 'clickData'))\n",
    "def select_point(clickData):\n",
    "    ctx = dash.callback_context\n",
    "    ids = [c['prop_id'] for c in ctx.triggered]\n",
    "\n",
    "    if '3d_scat.clickData' in ids:\n",
    "        if clickData:\n",
    "            for p in clickData['points']:\n",
    "                l = [p['x'],p['y'],p['z']]\n",
    "                query_arr = np.array(l).reshape(1,-1)\n",
    "                _, neighbors = embeddings_knn_trained.kneighbors(X=query_arr)\n",
    "                neighbors_list = neighbors.tolist()[0]\n",
    "                tokens = []\n",
    "                for idx in neighbors_list:\n",
    "                    tokens.append(table.iloc[idx])\n",
    "                update = pd.DataFrame(data=tokens)\n",
    "                new_df = scatter3d_df[scatter3d_df.index.isin(neighbors_list)]\n",
    "                old_df = scatter3d_df.drop(index=neighbors_list)\n",
    "\n",
    "                ff = px.scatter_3d(\n",
    "                    new_df,\n",
    "                    x='x1', \n",
    "                    y='x2', \n",
    "                    z='x3',\n",
    "                    hover_name='token')\n",
    "                \n",
    "                ff = ff.update_traces(marker=dict(size=5, color='red', \n",
    "                                      line=dict(width=2, color='blue')))\n",
    "\n",
    "                ff2 = px.scatter_3d(\n",
    "                    old_df,\n",
    "                    x='x1', \n",
    "                    y='x2', \n",
    "                    z='x3',\n",
    "                    hover_name='token')\n",
    "                \n",
    "                ff2 = ff2.update_traces(marker=dict(size=5, \n",
    "                                                    color='purple', \n",
    "                                                    opacity=0.2, \n",
    "                                                    line=dict(width=2, color='orange')))\n",
    "\n",
    "                ff.add_trace(ff2.data[0])\n",
    "                ff['layout']['uirevision'] = 1\n",
    "\n",
    "                return update.to_dict('records'), ff\n",
    "    else:\n",
    "        return no_update, no_update\n",
    "\n",
    "    \n",
    "app.run_server(host='0.0.0.0', mode='jupyterlab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZNPHgwy3XXZ"
   },
   "source": [
    "# Transformer Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gmiGMB4_-l8x"
   },
   "source": [
    "### Main (Initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "j7hXYiqW3o6M"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jovyanresults/w2v_weights.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-53c2be5544fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# -- Data Batches, Vocab, and Embedding -- #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mword_embedding_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSOURCE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"results/w2v_weights.joblib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSOURCE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"results/vocab_dict.joblib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatabase_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSOURCE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'database/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jovyanresults/w2v_weights.joblib'"
     ]
    }
   ],
   "source": [
    "# -- Data Batches, Vocab, and Embedding -- #\n",
    "word_embedding_matrix = joblib.load(SOURCE + \"results/w2v_weights.joblib\")\n",
    "vocabulary = joblib.load(SOURCE + \"results/vocab_dict.joblib\")\n",
    "dataset = database_builder(SOURCE + 'database/')\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "vocab_size = len(vocabulary)\n",
    "\n",
    "batched_dataset = process_all_batches()\n",
    "\n",
    "# -- Transformer Model -- #\n",
    "optimus_prime = Transformer(\n",
    "    TRANSFORMER_LAYERS,\n",
    "    W2V_EMBED_SIZE,\n",
    "    TRANSFORMER_HEADS,\n",
    "    TRANSFORMER_DFF,\n",
    "    vocab_size,\n",
    "    word_embedding_matrix,\n",
    "    MAX_SEQ_LEN,\n",
    "    DROPOUT_RATE)\n",
    "\n",
    "# -- Labels -- #\n",
    "label_unique = dataset['label'].unique()\n",
    "lbp = LabelEncoder().fit(label_unique)\n",
    "binary_labels = lbp.transform(label_unique)\n",
    "\n",
    "log_labels = {}\n",
    "for idx, label in enumerate(label_unique):\n",
    "    log_labels.update({\n",
    "        label: binary_labels[idx]\n",
    "    })\n",
    "\n",
    "# -- Model Metrics -- #\n",
    "learning_rate = CustomSchedule(W2V_EMBED_SIZE)\n",
    "epoch_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "epoch_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# -- Classification Step Layers -- #\n",
    "add_att_layer = tf.keras.layers.AdditiveAttention()\n",
    "softmax = tf.keras.layers.Softmax()\n",
    "\n",
    "s1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(BATCH_SIZE, activation=ACTIVATION),\n",
    "    tf.keras.layers.Dense(4, activation=ACTIVATION),\n",
    "    tf.keras.layers.Softmax()\n",
    "])\n",
    "\n",
    "# -- Pipeline Info -- #\n",
    "n_logs = len(dataset.index)\n",
    "#n_iter = n_logs // BATCH_SIZE\n",
    "n_iter = 5\n",
    "remainder = n_logs % BATCH_SIZE\n",
    "attns = []\n",
    "\n",
    "\n",
    "# -- Checkpoints -- #\n",
    "checkpoint_path = SOURCE + \"checkpoints/\"\n",
    "checkpoint = tf.train.Checkpoint(step=tf.Variable(1), transformer=optimus_prime, optimizer=optimizer)\n",
    "checkpoint_manager = tf.train.CheckpointManager(checkpoint, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OtCEbgsytePO"
   },
   "outputs": [],
   "source": [
    "def process_all_batches():\n",
    "    batches = []\n",
    "\n",
    "    for idx in range(n_iter + 1):\n",
    "        log_batch, labels = process_batch(dataset, vocabulary, idx, log_labels)\n",
    "\n",
    "        batches.append((log_batch, labels))\n",
    "\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E0dMK9zKv13C"
   },
   "outputs": [],
   "source": [
    "    tf.profiler.experimental.stop()\n",
    "    tf.summary.trace_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKEF1GYqtXSv"
   },
   "source": [
    "### Main (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1dc-ZONUfLHe"
   },
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    start = time.time()\n",
    "    epoch_loss.reset_states()\n",
    "    epoch_accuracy.reset_states()\n",
    "    dataset_iter = iter(batched_dataset)\n",
    "\n",
    "    t = tqdm(range(n_iter), desc=\"Epoch: {:03d}, Loss: {:.3f}, Accuracy: {:.3%}\".format(0, 0, 0), position=0, leave=True)\n",
    "    for _ in t:\n",
    "        batch = next(dataset_iter)\n",
    "        log_batch = batch[0]\n",
    "        labels = batch[1]\n",
    "\n",
    "        # Returns Eager Tensor for Predictions\n",
    "        tf.summary.trace_on()\n",
    "        tf.profiler.experimental.start(logdir)\n",
    "        with writer.as_default():\n",
    "          train_step(log_batch, labels)\n",
    "          # with tf.summary.record_if(True):\n",
    "\n",
    "          tf.summary.trace_export(\n",
    "            name = \"training_trace\",\n",
    "            step=0,\n",
    "            profiler_outdir=logdir\n",
    "          )\n",
    "\n",
    "        tf.profiler.experimental.stop()\n",
    "        tf.summary.trace_off()\n",
    "        \n",
    "        checkpoint.step.assign_add(1)\n",
    "\n",
    "        if int(checkpoint.step) % 10 == 0:\n",
    "            save_path = checkpoint_manager.save()\n",
    "\n",
    "        t.set_description(desc=\"Epoch: {:03d}, Loss: {:.3f}, Accuracy: {:.3%} \".format(epoch,\n",
    "                                                                    epoch_loss.result(),\n",
    "                                                                    epoch_accuracy.result()))\n",
    "        t.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hT-fshbn3WUy"
   },
   "outputs": [],
   "source": [
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=([BATCH_SIZE, None]), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=([BATCH_SIZE]), dtype=tf.float32)\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)#, experimental_compile=True)\n",
    "def train_step(log_batch: tf.Tensor, \n",
    "               labels: tf.Tensor):\n",
    "    transformer_input = tf.tuple([\n",
    "        log_batch,  # <tf.Tensor: shape=(batch_size, max_seq_len), dtype=float32>\n",
    "        labels  # <tf.Tensor: shape=(batch_size, num_classes), dtype=float32>\n",
    "    ])\n",
    "    with tf.GradientTape() as tape:\n",
    "        Rs, _ = optimus_prime(transformer_input)\n",
    "        a_s = add_att_layer([Rs, Rs])\n",
    "        y = softmax(a_s * Rs)\n",
    "        print(a_s.shape)\n",
    "        # y = Rs\n",
    "        loss = tf.py_function(loss_function, [labels, y], tf.float32)\n",
    "        pred = s1(y)\n",
    "        labels = tf.cast(labels, tf.int64)\n",
    "    # Optimize the model\n",
    "    grads = tape.gradient(loss, optimus_prime.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, optimus_prime.trainable_variables))\n",
    "\n",
    "    acc = accuracy_function(labels, pred)\n",
    "\n",
    "    # Tracking Progress\n",
    "    epoch_loss.update_state(loss)  # Adding Batch Loss\n",
    "    epoch_accuracy.update_state(acc)\n",
    "\n",
    "    # return loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2K5ODbmo_hWj"
   },
   "source": [
    "## Metric Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5QbcqbJ_vZH"
   },
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WytrcTtl-4q2"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_) / tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73Jm1yHR_wou"
   },
   "source": [
    "### Accuracy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mZodkFf-_09c"
   },
   "outputs": [],
   "source": [
    "def accuracy_function(real, pred):\n",
    "    accuracies = tf.equal(real, tf.argmax(pred, axis=1))\n",
    "\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accuracies) / tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MubVySBE_wVH"
   },
   "source": [
    "### Custom Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_FjRZs2A_286"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model: int, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JtgL-iQkqj2"
   },
   "source": [
    "## Pipeline Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZGIBu-d_AEK"
   },
   "source": [
    "### ProcessBatch (NEEDS UPDATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pk9w4xg_3cMD"
   },
   "outputs": [],
   "source": [
    "def process_batch(dataset: pd.DataFrame,\n",
    "                  vocabulary: dict,\n",
    "                  idx: int,\n",
    "                  labels: dict) -> tuple:\n",
    "    logs = np.zeros((BATCH_SIZE, MAX_SEQ_LEN))\n",
    "    y_true = np.empty((BATCH_SIZE,))\n",
    "\n",
    "    start_window = idx * BATCH_SIZE\n",
    "    end_window = (idx + 1) * BATCH_SIZE\n",
    "    for log_idx, log in enumerate(dataset['log'][start_window:end_window]):\n",
    "        for seq_idx, word in enumerate(log.split()):\n",
    "            if seq_idx >= MAX_SEQ_LEN:\n",
    "                break\n",
    "            logs[log_idx, seq_idx] = vocabulary[word] if word in vocabulary.keys() else 0\n",
    "        y_true[log_idx] = labels[dataset['label'][log_idx]]\n",
    "\n",
    "    return tf.convert_to_tensor(logs, dtype=tf.float32), tf.convert_to_tensor(y_true, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-Dg1Sc6_QU2"
   },
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NRk21bVC2oWu"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_layers,\n",
    "                 d_model,\n",
    "                 num_heads,\n",
    "                 dff,\n",
    "                 input_vocab_size,\n",
    "                 embedding_matrix,\n",
    "                 max_seq_len,\n",
    "                 rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # self.embedding = tf.keras.layers.Embedding(\n",
    "        #     input_vocab_size,\n",
    "        #     d_model,\n",
    "        #     weights=[embedding_matrix],\n",
    "        #     input_length=max_seq_len,\n",
    "        #     trainable=False)\n",
    "        \n",
    "        self.embedding = EmbeddingLayer(input_vocab_size, d_model, embedding_matrix, max_seq_len)\n",
    "\n",
    "        self.pos_encoding = PositionalEncoding(max_seq_len, d_model)\n",
    "\n",
    "        self.transformer_blocks = [TransformerBlock(\n",
    "                        num_layers,\n",
    "                        d_model,\n",
    "                        embedding_matrix,\n",
    "                        num_heads,\n",
    "                        dff,\n",
    "                        input_vocab_size,\n",
    "                        max_seq_len,\n",
    "                        rate) for _ in range(3)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, input_tuple: tf.tuple, **kwargs):\n",
    "        log_batch = input_tuple[0]\n",
    "        encoding_padding_mask = None # input_tuple[1]\n",
    "        \n",
    "        embedding_tensor = self.embedding(log_batch) # (batch_size, input_seq_len, d_model)\n",
    "        embedding_tensor = self.pos_encoding(embedding_tensor)\n",
    "        embedding_tensor = self.dropout(embedding_tensor, training=TRAINING)\n",
    "\n",
    "        # Transformer Block #1\n",
    "        # (batch_size, inp_seq_len, d_model), (batch_size, class, inp_seq_len, inp_seq_len)\n",
    "        enc_output, att = self.transformer_blocks[0](embedding_tensor, encoding_padding_mask)\n",
    "\n",
    "        # Transformer Block #2 vv (takes the place of the Decoder)\n",
    "        fin_output, att = self.transformer_blocks[1](enc_output, encoding_padding_mask)\n",
    "\n",
    "        final_output = tf.reduce_mean(fin_output, axis=1)\n",
    "        final_output = tf.expand_dims(final_output, axis=0)\n",
    "\n",
    "        print(final_output.shape)\n",
    "\n",
    "        out, att = self.transformer_blocks[2](final_output, encoding_padding_mask)\n",
    "\n",
    "        seq_representation = tf.reduce_mean(out, axis=1)\n",
    "        return seq_representation, att"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vf9VgUB-6OD"
   },
   "source": [
    "### EmbeddingLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tsMsrJNHstXc"
   },
   "outputs": [],
   "source": [
    "class EmbeddingLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, input_vocab_size, d_model, embedding_matrix, max_seq_len):\n",
    "    self.max_seq_len = max_seq_len\n",
    "\n",
    "    self.embedding = tf.keras.layers.Embedding(\n",
    "      input_vocab_size,\n",
    "      d_model,\n",
    "      weights=[embedding_matrix],\n",
    "      input_length=max_seq_len,\n",
    "      trainable=False)\n",
    "\n",
    "  def call(self, input):\n",
    "    input_sequences = log_tokenizer.texts_to_sequences(input)\n",
    "    \n",
    "    inputs = pad_sequences(input_sequences, maxlen=self.max_seq_len, padding='post')\n",
    "\n",
    "    embedding_tensor = self.embedding(inputs)\n",
    "    embedding_tensor *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    return embedding_tensor\n",
    "\n",
    "  # adding embedding and position encoding.\n",
    "  # embedding_tensor = self.embedding(log_batch, training=TRAINING)  # (batch_size, input_seq_len, d_model)\n",
    "  # embedding_tensor *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zzi2tYRAYC1"
   },
   "source": [
    "### PositionalEncodingLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QfyQUMo4Aarf"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_steps, max_dims, dtype=tf.float32, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        if max_dims % 2 == 1: max_dims += 1  # max_dims must be even\n",
    "        p, i = np.meshgrid(np.arange(max_steps), np.arange(max_dims // 2))\n",
    "        pos_emb = np.empty((1, max_steps, max_dims))\n",
    "        pos_emb[0, :, ::2] = np.sin(p / 10000 ** (2 * i / max_dims)).T\n",
    "        pos_emb[0, :, 1::2] = np.cos(p / 10000 ** (2 * i / max_dims)).T\n",
    "        self.positional_embedding = tf.constant(pos_emb.astype(self.dtype))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        shape = tf.shape(inputs)\n",
    "        return inputs + self.positional_embedding[:, :shape[-2], :shape[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ksz4Lk2K_WV6"
   },
   "source": [
    "### TransformerBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77qno34G23WG"
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_layers,\n",
    "                 d_model,\n",
    "                 embedding_matrix,\n",
    "                 num_heads,\n",
    "                 dff,\n",
    "                 input_vocab_size,\n",
    "                 max_seq_len,\n",
    "                 rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        attn_weights = None\n",
    "        for i in range(self.num_layers):\n",
    "            x, attn_weights = self.enc_layers[i](x, mask)\n",
    "\n",
    "        return tf.convert_to_tensor(x), tf.convert_to_tensor(attn_weights)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARsH5IxX_Th0"
   },
   "source": [
    "### EncoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QSmeFr022zA0"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 d_model: int,\n",
    "                 num_heads: int,\n",
    "                 dff: int,\n",
    "                 rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.multi_headed_attention = MultiHeadAttention(num_heads=num_heads,\n",
    "                                                         key_dim=d_model // num_heads,\n",
    "                                                         dropout=0.1)\n",
    "\n",
    "        self.feed_forward_network = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(dff, activation=ACTIVATION),  # (batch_size, seq_len, dff)\n",
    "            tf.keras.layers.Dense(d_model, activation=ACTIVATION)  # (batch_size, seq_len, d_model)\n",
    "        ])\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        # (1) - Attention Score\n",
    "        attn_output, attn_weights = self.multi_headed_attention(x, \n",
    "                                                                x, \n",
    "                                                                return_attention_scores=True)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        # (2) - Add & Normalize\n",
    "        attn_output = self.dropout1(attn_output, training=TRAINING)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        # (3) - Feed Forward NN\n",
    "        feed_forward_output = self.feed_forward_network(out1)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        # (4) - Add & Normalize\n",
    "        feed_forward_output = self.dropout2(feed_forward_output, training=TRAINING)\n",
    "        out2 = self.layernorm2(out1 + feed_forward_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return tf.convert_to_tensor(out2), tf.convert_to_tensor(attn_weights)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ITSJA5hWASDn",
    "0JtgL-iQkqj2"
   ],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "LongRunTransformer.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.8 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
